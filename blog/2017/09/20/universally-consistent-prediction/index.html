
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Universally Consistent Prediction - Que-sais je?</title>
  <meta name="author" content="yhli">

  
  <meta name="description" content="Introduction Can one predict the future well, without any subjective assumptions? Indeed, there are actually some prediction strategies that work &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://yenhuanli.github.io/blog/2017/09/20/universally-consistent-prediction">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Que-sais je?" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=Fjalla+One" rel="stylesheet" type="text/css">
<!--- MathJax Configuration -->
<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<!-- mathjax config similar to math.stackexchange -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$']],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  messageStyle: "none",
  "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
});
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

  
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-77006714-1', 'auto');
    ga('send', 'pageview');

  </script>



</head>

<body   class="collapse-sidebar sidebar-footer" >
  <header role="banner"><hgroup>
  <h1><a href="/">Que-sais je?</a></h1>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscribe" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS" target="_blank"><svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="25" height="25" viewbox="0 0 100 100"><path class="social" d="M 13.310204,73.332654 C 5.967347,73.332654 0,79.322448 0,86.621428 c 0,7.338776 5.967347,13.262246 13.310204,13.262246 7.370408,0 13.328572,-5.92245 13.328572,-13.262246 0,-7.29898 -5.958164,-13.288774 -13.328572,-13.288774 z M 0.01530612,33.978572 V 53.143878 C 12.493878,53.143878 24.229592,58.02347 33.068368,66.865306 41.894898,75.685714 46.767346,87.47449 46.767346,100 h 19.25 C 66.017346,63.592858 36.4,33.979592 0.01530612,33.978572 l 0,0 z M 0.03877552,0 V 19.17449 C 44.54796,19.17551 80.77551,55.437756 80.77551,100 H 100 C 100,44.87653 55.15102,0 0.03877552,0 z"></path></svg></a></li>
  
</ul>
  
  
  
  
  
  
  
  
  
  
    
      <form action="https://www.google.com/search" method="get">
        <fieldset role="search">
          <input type="hidden" name="sitesearch" value="yenhuanli.github.io" />
    
          <input class="search" type="text" name="q" results="0" placeholder="Search"/>
        </fieldset>
      </form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/about">About</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      
        <h1 class="entry-title">Universally Consistent Prediction</h1>
      
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2017-09-20T18:48:19+02:00'><span class='date'><span class='date-month'>Sep</span> <span class='date-day'>20</span><span class='date-suffix'>th</span>, <span class='date-year'>2017</span></span> <span class='time'>6:48 pm</span></time>
        
        
      </p>
    
  </header>


<div class="entry-content"><h3 id="introduction">Introduction</h3>

<p>Can one predict the future well, <em>without any subjective assumptions</em>? 
Indeed, there are actually some prediction strategies that work without any subjective assumption, and approach (arguably) the best possible performance in some sense.
This post introduces one such strategy described in <a href="https://arxiv.org/abs/cs/0606093">an article by V. Vovk</a>.</p>

<p>Consider the following protocol of <em>online prediction</em>. 
For $t = 1, 2, \ldots$,</p>

<ol>
  <li>Reality announces $x_t \in \mathcal{X}$.</li>
  <li>Predictor announces $\gamma_t \in \Gamma$.</li>
  <li>Reality announces $y_t \in \mathcal{Y}$.</li>
</ol>

<p>We assume the perfect information case; that is, all $x_t$’s, $\gamma_t$’s, and $y_t$’s, once announced, are known to both Reality and Predictor.</p>

<p><strong>Exercise.</strong> Find some real-life examples of this protocol. 
Notice that $\mathcal{X}$ can be the space of histories.</p>

<p>We measure the quality of prediction by a given loss function $\lambda: \mathcal{X} \times \Gamma \times \mathcal{Y} \to \mathbb{R}$, known to both Reality and Predictor. 
We will consider compact-type losses.</p>

<p><strong>Definition.</strong> A loss function is called compact-type, if for any compact sets $A \subseteq \mathcal{X}$ and $B \subseteq \mathcal{Y}$ and any $M \in \mathbb{R}$, there exists some compact set $C \subset \Gamma$, such that $\lambda ( x, \gamma, y ) &gt; M$ for any $x \in A$, $y \in B$, and $\gamma \notin C$.</p>

<p>A (possibly randomized) prediction strategy is a function $\psi: \mathcal{X} \to \Delta ( \Gamma )$, where $\Delta ( \Gamma )$ denotes the set of all probabiity measures on $\Gamma$. 
For each $t$, Predictor computes $Q_t := \psi( x_t )$, and chooses $\gamma_t \in \Gamma$ randomly according to $Q_t$.</p>

<p><strong>Definition.</strong> We say that a prediction strategy is continuous, if the associated function $\psi$ is continuous.</p>

<p><strong>Theorem 1 (<a href="https://arxiv.org/abs/cs/0606093">Vovk</a>).</strong> Suppose that $\mathcal{X}$ and $\mathcal{Y}$ are locally compact metric spaces, and $\Gamma$ is a metric space. 
Suppose that $\lambda$ is continuous and compact-type. 
Then for any $\varepsilon &gt; 0$, there exists a prediction strategy, such that if <script type="math/tex">\{ x_t \}</script> and <script type="math/tex">\{ y_t \}</script> are precompact,</p>

<script type="math/tex; mode=display">\limsup_{T \to \infty} \frac{1}{T} \sum_{t = 1}^T \left( \lambda ( x_t, \gamma_t, y_t ) - \lambda ( x_t, \tilde{\gamma_t}, y_t ) \right) \leq \varepsilon, \quad \text{a.s.} ,</script>

<p>where $( \tilde{\gamma_t} )_{t \in \mathbb{N}}$ is the sequence of predictions made by any continuous prediction strategy.</p>

<p>Any prediction strategy that achieves the theorem above is called universally consistent.</p>

<h3 id="ideas">Ideas</h3>

<p>The prediction strategy proposed by Vovk consists of two parts. 
Predictor first computes an estimate of the conditional probability distribution of $y_t$ given the history; then Predictor chooses the optimal $\gamma_t$ minimizing the estimated conditional expected loss.
Notice that, however, the online prediction protocol is completely deterministic; hence talking about the conditional probability and expected loss, rigorously speaking, is not legal in the sense of measure-theoretic probability.</p>

<p>The first part is called <em>probability forecasting</em>. 
The protocol of probability forecasting is as follows. 
For $t = 1, 2, \ldots$,</p>

<ol>
  <li>Reality announces $x_t \in \mathcal{X}$.</li>
  <li>Forecaster announces $P_t \in \Delta ( \mathcal{Y} )$.</li>
  <li>Reality announces $y_t \in \mathcal{Y}$.</li>
</ol>

<p><strong>Theorem 2 (<a href="https://arxiv.org/abs/cs/0606093">Vovk</a>).</strong> Suppose that $\mathcal{X}$ and $\mathcal{Y}$ are compact metric spaces.
There exists some forecasting strategy, such that</p>

<script type="math/tex; mode=display">\lim_{T \to \infty} \frac{1}{T} \sum_{t = 1}^T \left( f ( x_t, P_t, y_t ) - \int_{\mathcal{Y}} f ( x_t, P_t, y ) \, P_t ( \mathrm{d} y ) \right) = 0 ,</script>

<p>for any continuous function $f: \mathcal{X} \times \Delta ( \mathcal{Y} ) \times \mathcal{Y} \to \mathbb{R}$.</p>

<p>The forecasting strategy behind Theorem 2 is based on the existence of a universal RKHS $\mathcal{H}$ on $\mathcal{X} \times \Delta ( \mathcal{Y} ) \times \mathcal{Y}$, i.e., an RKHS dense in $C ( \mathcal{X} \times \Delta ( \mathcal{Y} ) \times \mathcal{Y} )$.
Following the framework of defensive forecasting, one can construct a forecasting strategy such that the inequality in Theorem 2 holds for all functions in $\mathcal{H}$. 
As $\mathcal{H}$ is dense in $C ( \mathcal{X} \times \Delta ( \mathcal{Y} ) \times \mathcal{Y} )$, one obtains Theorem 2.</p>

<p>Naively speaking, the second part corresponds to finding the randomized action that minimizes the conditional expected loss, i.e., computing</p>

<script type="math/tex; mode=display">\tilde{Q}_t \in \mathrm{argmin}_{Q \in \Delta( \Gamma )} \int_{\mathcal{Y}} \lambda ( x_t, Q, y ) P_t ( \mathrm{d} y ) ,</script>

<p>where $P_t$ is the output of probability forecasting, and</p>

<script type="math/tex; mode=display">\lambda ( x, Q, y ) := \int_{\Gamma} \lambda ( x, \gamma, y ) Q ( \mathrm{d} \gamma ) .</script>

<p>Then Predictor chooses $\gamma_t$ randomly according to $\tilde{Q}_t$.</p>

<p>Theorem 2 considers continuous functions, while $\tilde{Q}_t$ may not be continuously dependent on $(x_t, P_t)$. 
Therefore, we need to slightly modify the second part.
What Predictor actually does in the second part is to compute $Q_t := G ( x_t, P_t ) \in \Delta ( \Gamma )$, for some continuous function $G$ satisfying</p>

<script type="math/tex; mode=display">\int_{\mathcal{Y}} \lambda ( x_t, G( x_t, P_t ), y ) P_t ( \mathrm{d} y ) \leq \mathrm{argmin}_{Q \in \Delta( \Gamma )} \int_{\mathcal{Y}} \lambda ( x_t, Q, y ) P_t ( \mathrm{d} y ) + \delta</script>

<p>for some $\delta &gt; 0$.</p>

<p><strong>Lemma 1 (<a href="https://arxiv.org/abs/cs/0606093">Vovk</a>).</strong> Suppose that $\Gamma$ is a compact convex subset of a topological vector space. Such a continuous function $G$ exists for any $\delta &gt; 0$.</p>

<p>In Theorem 1, the conditions on $\mathcal{X}$, $\mathcal{Y}$, and $\Gamma$ are not as strict as those in Theorem 2 and Lemma 1.
This gap can be addressed by a doubling-like trick. 
Roughly speaking, Predictor starts with compact subsets $A \subseteq \mathcal{X}$ and $B \subseteq \mathcal{Y}$, and a compact convex subset $C \subseteq \Gamma$. 
Predictor implements the prediction strategy described above only on $A$, $B$, and $C$.
If Reality announces some $( x_t, y_t ) \notin A \times B$, Predictor enlarges $A$, $B$ and $C$ such that $( x_t, y_t )$ is contained.</p>

<ol>
  <li>If Predictor is forced to enlarge the sets for inifinitely many times, <script type="math/tex">\{ x_t \}</script> and <script type="math/tex">\{ y_t \}</script> cannot be both precompact.</li>
  <li>Otherwise, ultimately Predictor is working with some $A \subseteq \mathcal{X}$, $B \subseteq \mathcal{Y}$, and $C \subseteq \Gamma$, to which Theorem 2 and Lemma 1 apply.</li>
</ol>
</div>


  <footer>
    <p class="meta">
      
  



  <span class="byline author vcard">Authored by <span class="fn">
  
    yhli
  
  </span></span>


      




<time class='entry-date' datetime='2017-09-20T18:48:19+02:00'><span class='date'><span class='date-month'>Sep</span> <span class='date-day'>20</span><span class='date-suffix'>th</span>, <span class='date-year'>2017</span></span> <span class='time'>6:48 pm</span></time>
      
      


    </p>
    
      <div class="sharing">
  
  <a href="//twitter.com/share" class="twitter-share-button" data-url="http://yenhuanli.github.io/blog/2017/09/20/universally-consistent-prediction/" data-via="" data-counturl="http://yenhuanli.github.io/blog/2017/09/20/universally-consistent-prediction/" >Tweet</a>
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2017/05/05/mirror-descent-str/" title="Previous Post: Minimizing a Strongly Convex Function by Mirror Descent">&laquo; Minimizing a Strongly Convex Function by Mirror Descent</a>
      
      
        <a class="basic-alignment right" href="/blog/2017/09/22/calibrated-forecasting/" title="Next Post: Calibrated Forecasting">Calibrated Forecasting &raquo;</a>
      
    </p>
  </footer>
</article>


</div>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2017 - yhli -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a> | Themed with <a href="https://github.com/lucaslew/whitespace">Whitespace</a></span>
</p>

</footer>
  










  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
