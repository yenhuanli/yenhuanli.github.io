
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Aggregating Algorithm - Que-sais je?</title>
  <meta name="author" content="yhli">

  
  <meta name="description" content="This post is essentially a summary of some results in the classical paper “A game of prediction with expert advice” by V. Vovk. Definition. A game is &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://yenhuanli.github.io/blog/2017/03/02/aggregating-algorithm">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Que-sais je?" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=Fjalla+One" rel="stylesheet" type="text/css">
<!--- MathJax Configuration -->
<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<!-- mathjax config similar to math.stackexchange -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$']],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  messageStyle: "none",
  "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
});
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

  
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-77006714-1', 'auto');
    ga('send', 'pageview');

  </script>



</head>

<body   class="collapse-sidebar sidebar-footer" >
  <header role="banner"><hgroup>
  <h1><a href="/">Que-sais je?</a></h1>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscribe" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS" target="_blank"><svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="25" height="25" viewbox="0 0 100 100"><path class="social" d="M 13.310204,73.332654 C 5.967347,73.332654 0,79.322448 0,86.621428 c 0,7.338776 5.967347,13.262246 13.310204,13.262246 7.370408,0 13.328572,-5.92245 13.328572,-13.262246 0,-7.29898 -5.958164,-13.288774 -13.328572,-13.288774 z M 0.01530612,33.978572 V 53.143878 C 12.493878,53.143878 24.229592,58.02347 33.068368,66.865306 41.894898,75.685714 46.767346,87.47449 46.767346,100 h 19.25 C 66.017346,63.592858 36.4,33.979592 0.01530612,33.978572 l 0,0 z M 0.03877552,0 V 19.17449 C 44.54796,19.17551 80.77551,55.437756 80.77551,100 H 100 C 100,44.87653 55.15102,0 0.03877552,0 z"></path></svg></a></li>
  
</ul>
  
  
  
  
  
  
  
  
  
  
    
      <form action="https://www.google.com/search" method="get">
        <fieldset role="search">
          <input type="hidden" name="sitesearch" value="yenhuanli.github.io" />
    
          <input class="search" type="text" name="q" results="0" placeholder="Search"/>
        </fieldset>
      </form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/about">About</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      
        <h1 class="entry-title">Aggregating Algorithm</h1>
      
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2017-03-02T18:57:06+01:00'><span class='date'><span class='date-month'>Mar</span> <span class='date-day'>2</span><span class='date-suffix'>nd</span>, <span class='date-year'>2017</span></span> <span class='time'>6:57 pm</span></time>
        
        
      </p>
    
  </header>


<div class="entry-content"><p>This post is essentially a summary of some results in the classical paper <a href="http://dx.doi.org/10.1006/jcss.1997.1556">“A game of prediction with expert advice”</a> by V. Vovk.</p>

<p><strong>Definition.</strong> A <em>game</em> is a triple $( \Omega, \Gamma, \lambda )$, where $\Omega$ is the <em>outcome space</em>, $\Gamma$ is the <em>prediction space</em>, and $\lambda: \Omega \times \Gamma \to [0, \infty]$ is the <em>loss function</em>.</p>

<p>Consider the standard <em>learning with expert advice</em> setting, in which a <em>learner</em> tries to predict the outcomes of the <em>nature</em> sequentially, with the help of $n$ <em>experts</em>. 
Precisely speaking, at each trial $t \in \mathbb{N}$:</p>

<ol>
  <li>Each expert $i$ makes a prediction $\gamma_t (i)$, $1 \leq i \leq n$.</li>
  <li>The learner makes a prediction $\gamma_t \in \Gamma$.</li>
  <li>The nature chooses an outcome $\omega_t \in \Omega$.</li>
  <li>The learner suffers for the loss $\lambda ( \omega_t, \gamma_t )$.</li>
</ol>

<p>Notice that before making his prediction at the trial $t$, the learner has access to the past history of the nature (up to trial $t - 1$) and all of the experts (up to trial $t$).</p>

<p>For every $t \in \mathbb{N}$, let us define the learner’s accumulative loss as</p>

<script type="math/tex; mode=display">L_t := \lambda( \omega_1, \gamma_1 ) + \cdots + \lambda ( \omega_t, \gamma_t ),</script>

<p>and each expert’s accumulative loss as</p>

<script type="math/tex; mode=display">L_t ( i ) := \lambda( \omega_1, \gamma_1 ( i ) ) + \cdots + \lambda( \omega_t, \gamma_t ( i ) ), \quad i = 1, \ldots, n .</script>

<p>The learner’s goal is to make predictions almost as well as the <em>best expert</em>, in the sense that $L_t \leq L_t(i) + \varepsilon$ for all $i \leq n$, $t \in \mathbb{N}$, and some <em>small enough</em> $\varepsilon$.</p>

<p><strong>Definition.</strong> We say the game is <em>$\eta$-mixable</em>, if for any probability distribution $P$ on $\Gamma$, there exists a $\gamma^\star \in \Gamma$, such that</p>

<script type="math/tex; mode=display">\exp ( - \eta \lambda ( \omega, \gamma^\star ) ) \geq \int \exp ( - \eta \lambda( \omega, \gamma ) ) \, P( \mathrm{d} \gamma ), \quad \text{for all } \omega \in \Omega . \notag</script>

<p><strong>Remark.</strong> By Jensen’s inequality, if the mapping $\gamma \mapsto \exp ( - \eta \lambda ( \omega, \gamma ) )$ is concave for all $\omega \in \Omega$, then the game is $\eta$-mixable.
Any such loss function $\lambda$ is called <em>exp-concave</em>. 
Obviously, one can simply choose $\gamma^\star = \int \gamma \, P ( \mathrm{d} \gamma )$ if the loss is exp-concave.</p>

<p><strong>Proposition.</strong> <em>If a game is $\eta$-mixable, there exists a prediction algorithm for the learner, such that</em></p>

<script type="math/tex; mode=display">L_t \leq L_t ( i ) + \eta^{-1} \ln n , \quad \text{for all } i \leq n .</script>

<p>One such algorithm is the <em>aggregating algorithm (AA)</em>, first introduced in the paper <a href="http://vovk.net/aa/index.html">“Aggregating strategies”</a> by V. Vovk.
Let $( \pi_0 ( i ) )_{i \leq n}$ be a probability vector whose entries are all non-zero. 
At each trial $t \in \mathbb{N}$, the AA outputs a prediction $\gamma_t \in \Gamma$ satisfying</p>

<script type="math/tex; mode=display">\exp ( - \eta \lambda ( \omega_t, \gamma_t ) ) \geq \sum_{i \leq n} \pi_{t - 1} ( i ) \exp ( - \eta \lambda( \omega_t, \gamma_t ( i ) ) ) ,</script>

<p>and after observing $\omega_t$, the AA updates the probability vector as</p>

<script type="math/tex; mode=display">\pi_t ( i ) := z_t^{-1} \pi_{t - 1} ( i ) \exp ( - \eta \, \lambda ( \omega_t, \gamma_t ( i ) ) ) , \quad \text{for all } i \leq n ,</script>

<p>where $z_t$ is a normalizing constant such that $( \pi_t (i) )_{i \leq n}$ is also a probability vector.
Because of the $\eta$-mixability assumption, the AA is well-defined.</p>

<p><strong>Lemma.</strong> For each $t \in \mathbb{N}$, one has</p>

<script type="math/tex; mode=display">\exp ( - \eta L_t ) \geq \sum_{i \leq n} \pi_0 ( i ) \, \exp ( - \eta L_t ( i ) ) .</script>

<p><strong>Proof.</strong> We prove by induction. 
Obviously, the inequality holds for $t = 0$ (for which we set $L_t = L_t (i) = 0$ for all $i \leq n$).
Assume the inequality to be proved holds for $t = T$.
We write</p>

<script type="math/tex; mode=display">\exp ( - \eta L_{T + 1} ) = \exp ( - \eta L_T ) \exp ( - \eta \lambda ( \omega_{T + 1}, \gamma_{T + 1}(i) ) )</script>

<p>By the definition of the AA, the RHS is bounded below by</p>

<script type="math/tex; mode=display">\exp ( - \eta L_T ) \frac{ \sum_{i \leq n} \exp ( - \eta \lambda ( \omega_{T+1}, \lambda_{T+1} ( i ) ) ) \, \pi_0 ( i ) \, \exp ( - \eta L_T ( i ) ) }{ \sum_{i \leq n} \pi_0 ( i ) \, \exp ( - \eta L_T ( i ) ) } .</script>

<p>By assumption, the RHS can be further bounded below by</p>

<script type="math/tex; mode=display">\sum_{i \leq n} \exp ( - \eta \lambda ( \omega_{T+1}, \lambda_{T+1} ( i ) ) ) \, \pi_0 ( i ) \, \exp ( - \eta L_{T} ( i ) ) = \sum_{i \leq n} \pi_0 ( i ) \exp ( \eta L_{T+1} ( i ) ) .</script>

<p>This proves the lemma. <em>Q.E.D.</em></p>

<p>By the lemma, we have</p>

<script type="math/tex; mode=display">\exp ( - \eta L_t ) \geq \pi_0 ( i ) \, \exp ( - \eta L_t ( i ) ) , \quad \text{for all } i \leq n .</script>

<p>Hence we obtain</p>

<script type="math/tex; mode=display">L_t \leq L_t ( i ) + \frac{1}{ \eta } \log \left( \frac{1}{ \pi_0 ( i ) } \right) , \quad \text{for all} i \leq n.</script>

<p>Choosing $\pi_0 ( i ) = 1 / n$ for all $i$ (the uniform distribution) proves the proposition.</p>
</div>


  <footer>
    <p class="meta">
      
  



  <span class="byline author vcard">Authored by <span class="fn">
  
    yhli
  
  </span></span>


      




<time class='entry-date' datetime='2017-03-02T18:57:06+01:00'><span class='date'><span class='date-month'>Mar</span> <span class='date-day'>2</span><span class='date-suffix'>nd</span>, <span class='date-year'>2017</span></span> <span class='time'>6:57 pm</span></time>
      
      


    </p>
    
      <div class="sharing">
  
  <a href="//twitter.com/share" class="twitter-share-button" data-url="http://yenhuanli.github.io/blog/2017/03/02/aggregating-algorithm/" data-via="" data-counturl="http://yenhuanli.github.io/blog/2017/03/02/aggregating-algorithm/" >Tweet</a>
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2016/12/12/interesting-talks-in-nips-2016/" title="Previous Post: Some Interesting Talks at NIPS 2016">&laquo; Some Interesting Talks at NIPS 2016</a>
      
      
        <a class="basic-alignment right" href="/blog/2017/03/19/hedge/" title="Next Post: Hedge Algorithm">Hedge Algorithm &raquo;</a>
      
    </p>
  </footer>
</article>


</div>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2017 - yhli -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a> | Themed with <a href="https://github.com/lucaslew/whitespace">Whitespace</a></span>
</p>

</footer>
  










  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
